import os
import re
import shutil
import tempfile
import threading
import unicodedata
from datetime import datetime
from pathlib import Path

import pandas as pd
import xlwings as xw
from celery import shared_task
from filelock import FileLock
from playwright.sync_api import sync_playwright

from src.core.config import settings
from src.robot.KyushuOsaka.api import APISharePoint
from src.robot.KyushuOsaka.automation import PowerApp, SharePoint


def Fname(path: str):
    import time

    from pywinauto import Desktop
    from pywinauto.application import Application

    while True:
        found = False
        for win in Desktop(backend="win32").windows():
            if win.window_text() == "Browse":
                found = True
                break
        if found:
            break
        time.sleep(0.5)
    while True:
        app = Application(backend="win32").connect(title_re="Browse")
        dialog = app.window(title_re="Browse")
        dialog.wait("ready", timeout=10)
        root_window: int = dialog.handle
        AddressInput = dialog.child_window(
            class_name="Edit",
            control_id=1152,
        )
        AddressInput.wait("enabled", timeout=10)
        AddressInput.set_edit_text(path)
        time.sleep(0.5)
        OpenButton = dialog.child_window(
            class_name="Button",
            control_id=1,
        )
        OpenButton.wait("enabled", timeout=10)
        OpenButton.click()
        time.sleep(0.5)
        still_exists = any(win.handle == root_window for win in Desktop(backend="win32").windows())
        if still_exists:
            time.sleep(0.5)
            continue
        else:
            break


@shared_task(bind=True)
def kyushu_osaka(
    self,
    process_date: datetime,
    kyushu: bool | str = True,
    osaka: bool | str = True,
):
    # X·ª≠ l√≠ ƒë·∫ßu v√†o
    if isinstance(process_date, str):
        process_date = datetime.strptime(process_date, "%Y-%m-%d %H:%M:%S.%f").date()
    if isinstance(kyushu, str):
        if kyushu.lower() == "false":
            kyushu = False
        elif kyushu.lower() == "true":
            kyushu = True
        else:
            kyushu = False
    if isinstance(osaka, str):
        if osaka.lower() == "false":
            osaka = False
        elif osaka.lower() == "true":
            osaka = True
        else:
            osaka = False
    # -------------
    factory = []
    if kyushu:
        factory.append("‰πùÂ∑û")
    if osaka:
        factory.append("Â§ßÈò™")
    # -------------
    api = APISharePoint(
        TENANT_ID=settings.API_SHAREPOINT_TENANT_ID,
        CLIENT_ID=settings.API_SHAREPOINT_CLIENT_ID,
        CLIENT_SECRET=settings.API_SHAREPOINT_CLIENT_SECRET,
    )
    # --- #
    folder_id = None
    items = api.get_item_from_another_item(
        "nskkogyo.sharepoint.com,f8711c8d-9046-4e1c-9de9-e720d1c0c797,90e7b19b-ba14-4986-9e05-cbc7e7358c90",  # UP
        "b!jRxx-EaQHE6d6ecg0cDHl5ux55AUuoZJngXLx-c1jJCx-m83m_1wTqubHf8e5WFu",  # ....
        "01NRWYYNB7F5WKOEZTLRCISBYBBWMFETFG",  # „Éá„Éº„ÇøUP‰∏ÄË¶ß
    ).get("value")
    for item in items:
        if item.get("name") == f"{int(process_date.month)}Êúà{int(process_date.day)}Êó•":
            folder_id = item.get("id")
            break
    if folder_id is None:
        raise FileNotFoundError("Kh√¥ng t√¨m th·∫•y folder")
    # --- #
    files = api.get_item_from_another_item(
        "nskkogyo.sharepoint.com,f8711c8d-9046-4e1c-9de9-e720d1c0c797,90e7b19b-ba14-4986-9e05-cbc7e7358c90",
        "b!jRxx-EaQHE6d6ecg0cDHl5ux55AUuoZJngXLx-c1jJCx-m83m_1wTqubHf8e5WFu",
        folder_id,
    ).get("value")
    if not files:
        raise FileNotFoundError("Kh√¥ng t√¨m th·∫•y file data")
    files = [(file.get("id"), file.get("name")) for file in files]
    # --- #
    if (
        len(
            [
                (id, name)
                for id, name in files
                if isinstance(name, str) and name.lower().endswith((".xls", ".xlsx", ".xlsm"))
            ]
        )
        != 1
    ):
        raise FileNotFoundError("Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c file data")
    # --- #
    temp_file = [
        (id, name) for id, name in files if isinstance(name, str) and name.lower().endswith((".xls", ".xlsx", ".xlsm"))
    ]
    item_id = temp_file[0][0]
    item_name = temp_file[0][1]
    # --- #
    macro_file = "src/robot/KyushuOsaka/resource/„Éû„ÇØ„É≠„ÉÅ„Çß„ÉÉ„ÇØ(240819ver).xlsm"

    item_id = item_id
    driver_id = folder_id
    site_id = "nskkogyo.sharepoint.com,f8711c8d-9046-4e1c-9de9-e720d1c0c797,90e7b19b-ba14-4986-9e05-cbc7e7358c90"
    # --- item --- #
    file: dict = {
        "site_id": site_id,
        "drive_id": driver_id,
        "item_id": item_id,
        "item_name": item_name,
    }
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=False,
            args=[
                "--start-maximized",
            ],
        )
        context = browser.new_context(no_viewport=True)
        with (
            SharePoint(
                domain=settings.SHAREPOINT_DOMAIN,
                username=settings.SHAREPOINT_EMAIL,
                password=settings.SHAREPOINT_PASSWORD,
                playwright=p,
                browser=browser,
                context=context,
            ) as sp,
            PowerApp(
                username=settings.POWER_APP_USERNAME,
                password=settings.POWER_APP_PASSWORD,
                playwright=p,
                browser=browser,
                context=context,
            ),
            tempfile.TemporaryDirectory() as temp_dir,
        ):
            while True:
                drive_id, _ = api.download_item(
                    site_id=file.get("site_id"),
                    breadcrumb=f"„Éá„Éº„ÇøUP‰∏ÄË¶ß/{int(process_date.month)}Êúà{int(process_date.day)}Êó•/{file.get("item_name")}",
                    save_to=temp_dir,
                )
                data = pd.read_excel(io=os.path.join(temp_dir, file.get("item_name")), sheet_name="„Éá„Éº„ÇøUPÁä∂Ê≥Å")
                data.index = data.index + 2
                mask_factory = data["Âá∫Ëç∑Â∑•Â†¥"].isin(factory)
                mask_r_empty = data["R_Status"].isna() | data["R_Status"].astype(str).str.strip().eq("")
                mask_d_empty = data["DATAUPÁä∂Ê≥Å"].isna() | data["DATAUPÁä∂Ê≥Å"].astype(str).str.strip().eq("")
                data = data[mask_factory & mask_r_empty & mask_d_empty]
                if data.shape[0] == 0:
                    return
                suffix_name = f"{process_date.strftime("%m-%d")}Á¥çÊùê"
                for index, row in data.iterrows():
                    api.write(
                        site_id=file.get("site_id"),
                        drive_id=drive_id,
                        item_id=file.get("item_id"),
                        range=f"E{index}",
                        data=[["ƒêang x·ª≠ l√≠"]],
                        sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                    )
                    if pd.isna(row["Ë≥áÊñô„É™„É≥„ÇØ"]):
                        api.write(
                            site_id=file.get("site_id"),
                            drive_id=drive_id,
                            item_id=file.get("item_id"),
                            range=f"E{index}",
                            data=[["Kh√¥ng c√≥ link data"]],
                            sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                        )
                        break
                    if pd.isna(row["Èöé"]):
                        api.write(
                            site_id=file.get("site_id"),
                            drive_id=drive_id,
                            item_id=file.get("item_id"),
                            range=f"E{index}",
                            data=[["Kh√¥ng c√≥ link data"]],
                            sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                        )
                        break
                    breadcrumb = sp.get_breadcrumb(row["Ë≥áÊñô„É™„É≥„ÇØ"])
                    if breadcrumb[-1].endswith("Á¥çÊùê"):
                        api.write(
                            site_id=file.get("site_id"),
                            drive_id=drive_id,
                            item_id=file.get("item_id"),
                            range=f"E{index}",
                            data=[["T√™n folder c√≥ ghi ng√†y"]],
                            sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                        )
                        break
                    download_path = os.path.join(temp_dir, str(int(row["Ê°à‰ª∂Áï™Âè∑"])))
                    shutil.rmtree(download_path, ignore_errors=True)
                    downloads = sp.download(
                        url=row["Ë≥áÊñô„É™„É≥„ÇØ"],
                        file=re.compile(r".*\.(xls|xlsx|xlsm|xlsb|xml|xlt|xltx|xltm|xlam|pdf)$", re.IGNORECASE),
                        steps=[re.compile("^‚òÖ„Éá„Éº„Çø$")],
                        save_to=download_path,
                    )
                    if not downloads:
                        api.write(
                            site_id=file.get("site_id"),
                            drive_id=drive_id,
                            item_id=file.get("item_id"),
                            range=f"E{index}",
                            data=[["Kh√¥ng ƒë·ªß data"]],
                            sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                        )
                        break
                    count_floor = len(row["Èöé"].split(",")) if hasattr(row["Èöé"], "split") else None
                    if count_floor is None:
                        api.write(
                            site_id=file.get("site_id"),
                            drive_id=drive_id,
                            item_id=file.get("item_id"),
                            range=f"E{index}",
                            data=[["L·ªói: ki·ªÉm tra c·ªôt Èöé"]],
                            sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                        )
                        break
                    excel_files = len(
                        [
                            f
                            for f in downloads
                            if re.compile(r".*\.(xls|xlsx|xlsm|xlsb|xml|xlt|xltx|xltm|xlam)$", re.IGNORECASE).match(f)
                        ]
                    )
                    pdf_files = len([f for f in downloads if re.compile(r".*\.pdf$", re.IGNORECASE).match(f)])
                    if pdf_files != 1:
                        api.write(
                            site_id=file.get("site_id"),
                            drive_id=drive_id,
                            item_id=file.get("item_id"),
                            range=f"E{index}",
                            data=[[f"{pdf_files} file PDF"]],
                            sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                        )
                        break
                    if excel_files < count_floor:
                        api.write(
                            site_id=file.get("site_id"),
                            drive_id=drive_id,
                            item_id=file.get("item_id"),
                            range=f"E{index}",
                            data=[[f"{len(excel_files)} file / {count_floor} floors"]],
                            sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                        )
                        break
                    # --- Ki·ªÉm tra t√™n file --- #
                    isError: bool = False
                    for downloaded in downloads:
                        downloaded_file = unicodedata.normalize("NFKC", downloaded)
                        if not any(
                            part in downloaded_file
                            for part in re.split(r"[ \u3000„Éª\u2018]+", unicodedata.normalize("NFKC", breadcrumb[-1]))
                        ):
                            isError = True
                            break
                    if isError:
                        api.write(
                            site_id=file.get("site_id"),
                            drive_id=drive_id,
                            item_id=file.get("item_id"),
                            range=f"E{index}",
                            data=[["L·ªói filename"]],
                            sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                        )
                        break
                    # --- Ki·ªÉm tra macro
                    os.makedirs(os.path.join(download_path, "excel"), exist_ok=True)
                    os.makedirs(os.path.join(download_path, "pdf"), exist_ok=True)
                    while True:
                        for download in downloads:
                            f = os.path.basename(download)
                            if re.compile(r".*\.(xls|xlsx|xlsm|xlsb|xml|xlt|xltx|xltm|xlam)$", re.IGNORECASE).match(f):
                                shutil.move(
                                    src=download,
                                    dst=os.path.join(os.path.dirname(downloads[0]), "excel"),
                                )
                            else:
                                shutil.move(
                                    src=download,
                                    dst=os.path.join(os.path.dirname(downloads[0]), "pdf"),
                                )
                        if os.listdir(download_path) == ["excel", "pdf"]:
                            break
                    try:
                        with FileLock("macro.lock", timeout=300):
                            app = xw.App(visible=False)
                            wb_macro = app.books.open(macro_file)
                            threading.Thread(
                                target=Fname, args=(os.path.abspath(os.path.join(download_path, "excel")),)
                            ).start()
                            wb_macro.macro("Fname")()
                            # Fopen
                            wb_macro.macro("Fopen")()
                            wb_macro.save()
                            wb_macro.close()
                            app.quit()
                    except Exception:
                        api.write(
                            site_id=file.get("site_id"),
                            drive_id=drive_id,
                            item_id=file.get("item_id"),
                            range=f"E{index}",
                            data=[["L·ªói: Ch·∫°y macro l·ªói"]],
                            sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                        )
                        break
                    if row["Âá∫Ëç∑Â∑•Â†¥"] == "‰πùÂ∑û":
                        if not sp.upload(
                            url="https://nskkogyo.sharepoint.com/sites/kyuusyuukouzyou",
                            files=[f for f in Path(download_path).rglob("*") if f.is_file()],
                            steps=[
                                re.compile("^‰πùÂ∑ûÂ∑•Â†¥ Ë£ΩÈÄ†„Éá„Éº„Çø„Éº$"),
                                re.compile(f"{int(process_date.month)}Êúà{int(process_date.day)}Êó•ÈÖçÈÄÅÂàÜ"),
                                re.compile(r"^Á¢∫ÂÆö„Éá„Éº„Çø\(„Éá„Éº„ÇøÁ¢∫ÂÆöÊó•11ÊôÇÂçä‰ª•Èôç„ÅØ„Éï„Ç©„É´„ÉÄ„ÅÆÂ§ñ„Å∏UP\)$"),
                            ],
                        ):
                            api.write(
                                site_id=file.get("site_id"),
                                drive_id=drive_id,
                                item_id=file.get("item_id"),
                                range=f"E{index}",
                                data=[["L·ªói: Up Data"]],
                                sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                            )
                            break
                    elif row["Âá∫Ëç∑Â∑•Â†¥"] == "Â§ßÈò™":
                        if not sp.upload(
                            url="https://nskkogyo.sharepoint.com/sites/yanase/Shared Documents/Forms/AllItems.aspx?id=/sites/yanase/Shared Documents/Â§ßÈò™Â∑•Â†¥„ÄÄË£ΩÈÄ†„Éá„Éº„Çø",  # noqa: E501
                            files=[f for f in Path(download_path).rglob("*") if f.is_file()],
                            steps=[
                                re.compile(rf"^{process_date.month}(Êúà|Êó•){process_date.day}Êó•$"),
                                re.compile(r"^üîπÈñ¢Ë•øÂ∑•Â†¥Á¢∫ÂÆö„Éá„Éº„Çøüîπ"),
                            ],
                        ):
                            api.write(
                                site_id=file.get("site_id"),
                                drive_id=drive_id,
                                item_id=file.get("item_id"),
                                range=f"E{index}",
                                data=[["L·ªói: Up Data"]],
                                sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                            )
                            break
                    else:
                        api.write(
                            site_id=file.get("site_id"),
                            drive_id=drive_id,
                            item_id=file.get("item_id"),
                            range=f"E{index}",
                            data=[["L·ªói: ki·ªÉm tra x∆∞·ªüng"]],
                            sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                        )
                        break
                    if not sp.rename_breadcrumb(
                        url=row["Ë≥áÊñô„É™„É≥„ÇØ"],
                        new_name=f"{breadcrumb[-1]} {suffix_name}",
                    ):
                        api.write(
                            site_id=file.get("site_id"),
                            drive_id=drive_id,
                            item_id=file.get("item_id"),
                            range=f"E{index}",
                            data=[["Ch∆∞a c√≥ tr√™n Power App | L·ªói: ƒë·ªïi t√™n folder"]],
                            sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                        )
                    else:
                        api.write(
                            site_id=file.get("site_id"),
                            drive_id=drive_id,
                            item_id=file.get("item_id"),
                            range=f"E{index}",
                            data=[["Ch∆∞a c√≥ tr√™n Power App"]],
                            sheet="„Éá„Éº„ÇøUPÁä∂Ê≥Å",
                        )
                    break
