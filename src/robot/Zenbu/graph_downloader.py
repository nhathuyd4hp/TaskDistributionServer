# --- graph_downloader.py ---

import logging
import os

import requests
from config import BASE_URL
from graph_searcher import list_children, search_anken_folder
from Token_Manager import get_access_token


def download_pdf(download_url, save_path):
    """
    Download a single file from its download URL.
    """
    try:
        resp = requests.get(download_url, stream=True)
        resp.raise_for_status()
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        with open(save_path, "wb") as f:
            for chunk in resp.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        logging.info(f"âœ… Saved {os.path.basename(save_path)} successfully.")
    except Exception as e:
        logging.error(f"âŒ Failed to download {os.path.basename(save_path)}: {e}")


def download_files_inside_folder(drive_id, folder_id, local_folder_path):
    """
    Download only PDF and Excel files DIRECTLY inside å‰²ä»˜å›³ (no recursion into subfolders).
    """
    os.makedirs(local_folder_path, exist_ok=True)
    allowed_extensions = (".pdf", ".xls")  # Extend if needed
    downloaded_count = 0  # âœ… Track count

    url = f"{BASE_URL}/drives/{drive_id}/items/{folder_id}/children"
    headers = {"Authorization": f"Bearer {get_access_token()}"}

    while url:
        resp = requests.get(url, headers=headers)
        resp.raise_for_status()
        data = resp.json()

        for item in data.get("value", []):
            # ğŸ“Œ Only files (not folders)
            if "folder" not in item:
                file_name = item["name"]
                if file_name.lower().endswith(allowed_extensions):
                    download_url = item["@microsoft.graph.downloadUrl"]
                    save_path = os.path.join(local_folder_path, file_name)
                    download_pdf(download_url, save_path)
                    downloaded_count += 1  # âœ… Increment
                else:
                    logging.info(f"â© Skipped non-target file: {file_name}")
            else:
                logging.info(f"ğŸ“‚ Skipped subfolder: {item['name']}")

        url = data.get("@odata.nextLink", None)

    if downloaded_count == 0:
        raise Exception("âŒ å‰²ä»˜å›³ folder found but no files downloaded!")


def download_folder_by_anken(anken_number, local_folder_path):
    """
    Handles outliers where the search result itself is å‰²ä»˜å›³ folder.
    """
    anken_info = search_anken_folder(anken_number)
    if not anken_info:
        raise Exception(f"âŒ No Anken folder found for: {anken_number}")

    drive_id = anken_info["parentReference"]["driveId"]
    folder_id = anken_info["id"]
    folder_name = anken_info["name"]

    # Case A: Anomaly â€” the search result IS å‰²ä»˜å›³ folder
    if "å‰²ä»˜å›³" in folder_name or "å‰²ä»˜å›³ãƒ»ã‚¨ã‚¯ã‚»ãƒ«" in folder_name:
        logging.warning(f"âš ï¸ Anomaly: Got å‰²ä»˜å›³ folder directly from search result: {folder_name}")
        download_files_inside_folder(drive_id, folder_id, local_folder_path)
        return

    # Case B: Normal â€” search inside children for å‰²ä»˜å›³
    children = list_children(drive_id, folder_id)
    target_folder_id = None

    for item in children:
        child_name = item.get("name", "")
        if "å‰²ä»˜å›³" in child_name or "å‰²ä»˜å›³ãƒ»ã‚¨ã‚¯ã‚»ãƒ«" in child_name:
            target_folder_id = item["id"]
            logging.info(f"ğŸ“‚ Found å‰²ä»˜å›³ in subfolders: {child_name}")
            break

    if not target_folder_id:
        logging.warning(f"ğŸš« No folder containing 'å‰²ä»˜å›³' found under {anken_number}")
        logging.warning(f"ğŸ“ Subfolders found: {[item.get('name') for item in children]}")
        raise Exception(f"âŒ No folder containing 'å‰²ä»˜å›³' found under {anken_number}")

    download_files_inside_folder(drive_id, target_folder_id, local_folder_path)
    logging.info(f"âœ… Downloaded å‰²ä»˜å›³ successfully for {anken_number}")
